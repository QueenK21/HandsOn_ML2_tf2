{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11장\n",
    "### 11-1, 11-3\n",
    "----\n",
    "\n",
    "### Optimizer, Activation, Initializer를 조합하여 모델을 만들고 평가해 봅니다.\n",
    "\n",
    "* 수렴이 언제부터 시작되나요? \n",
    "\n",
    "* 모델의 성능은 어떤가요?\n",
    "\n",
    "* 전체 훈련 속도는 몇인가요? \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 0 ] \n",
    "\n",
    "* CIFAR10 데이터셋을 불러오세요. keras.datasets.cifar10.load_ data()를 사용하여 데이터를 적재할 수 있습니다.\n",
    "* 데이터셋의 차원을 확인해봅시다.\n",
    "* Dense layer을 사용하기 때문에 데이터의 shape을 1차원으로 바꿔야 합니다. ( np.reshape(데이터, (바꿀shape) ) 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "\n",
    "x_train = np.reshape(x_train, (50000, 32*32*3))  \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n",
    "x_test = np.reshape(x_test, (10000, 32*32*3))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "\n",
    "pixel_means = x_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = x_train.std(axis=0, keepdims=True)\n",
    "\n",
    "#pixel_means_test = x_test.mean(axis=0, keepdims=True)\n",
    "#pixel_stds_test = x_test.mean(axis=0, keepdims=True)\n",
    "\n",
    "x_train_scaled = (x_train - pixel_means) / pixel_stds\n",
    "x_test_scaled = (x_test - pixel_means) / pixel_stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [ 1 ]\n",
    "\n",
    "* **100**개의 뉴런을 가진 **은닉층** **20개**를 쌓아 심층 신경망을 만듭니다.\n",
    "* 모든 은닉층의 initializer는 **He 초기화**를, 활성화 함수는 **Relu** 함수를 사용합니다.\n",
    "* 출력층은 **10개**의 뉴런과 **소프트맥스 활성화** 함수를 사용합니다. \n",
    "* 출력층에서는 Initializer를 사용하지 않습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_1():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer((32*32*3)))\n",
    "\n",
    "    for _ in range(20):\n",
    "        model.add(tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer='he_normal'))  \n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1 )\n",
    "\n",
    "* 옵티마이저는 **Adam**를 사용합니다. \n",
    "* 모델 저장 이름은 **1-1_model.h5** 로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9719 - accuracy: 0.2556 - val_loss: 1.8558 - val_accuracy: 0.3018\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8363 - accuracy: 0.3029 - val_loss: 1.8148 - val_accuracy: 0.3105\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7655 - accuracy: 0.3363 - val_loss: 1.7783 - val_accuracy: 0.3483\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7152 - accuracy: 0.3715 - val_loss: 1.7181 - val_accuracy: 0.3773\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6479 - accuracy: 0.4026 - val_loss: 1.6753 - val_accuracy: 0.3992\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6035 - accuracy: 0.4195 - val_loss: 1.6855 - val_accuracy: 0.3923\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5745 - accuracy: 0.4394 - val_loss: 1.6550 - val_accuracy: 0.4097\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5318 - accuracy: 0.4537 - val_loss: 1.5996 - val_accuracy: 0.4362\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4974 - accuracy: 0.4669 - val_loss: 1.6245 - val_accuracy: 0.4243\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4667 - accuracy: 0.4805 - val_loss: 1.5992 - val_accuracy: 0.4326\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4461 - accuracy: 0.4870 - val_loss: 1.5939 - val_accuracy: 0.4481\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4171 - accuracy: 0.4997 - val_loss: 1.5532 - val_accuracy: 0.4547\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3900 - accuracy: 0.5076 - val_loss: 1.5817 - val_accuracy: 0.4565\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3726 - accuracy: 0.5143 - val_loss: 1.5601 - val_accuracy: 0.4535\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3378 - accuracy: 0.5290 - val_loss: 1.5555 - val_accuracy: 0.4734\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3321 - accuracy: 0.5285 - val_loss: 1.5113 - val_accuracy: 0.4745\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3094 - accuracy: 0.5379 - val_loss: 1.5506 - val_accuracy: 0.4619\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2785 - accuracy: 0.5503 - val_loss: 1.5546 - val_accuracy: 0.4677\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2627 - accuracy: 0.5543 - val_loss: 1.5507 - val_accuracy: 0.4779\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2428 - accuracy: 0.5609 - val_loss: 1.5652 - val_accuracy: 0.4743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd659d89940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 생성\n",
    "model=make_model_1()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"1-1_model.h5\", save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_scaled, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          callbacks=[model_checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2 )\n",
    "\n",
    "* 옵티마이저는 **Adam**을 사용합니다. Adam의 파라미터 **beta1**, **beta2**를 0.9, 0.999로 초기화 합니다. \n",
    "* 콜백 ModelCheckpoint의 저장 이름을 **1-2_model.h5**로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9855 - accuracy: 0.2421 - val_loss: 1.8664 - val_accuracy: 0.2948\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8146 - accuracy: 0.3132 - val_loss: 1.7937 - val_accuracy: 0.3350\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 1.7399 - accuracy: 0.3514 - val_loss: 1.7598 - val_accuracy: 0.3349\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6752 - accuracy: 0.3817 - val_loss: 1.6803 - val_accuracy: 0.3842\n",
      "Epoch 5/20\n",
      "1044/1250 [========================>.....] - ETA: 0s - loss: 1.6323 - accuracy: 0.3912"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-85a27672d193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 모델 훈련\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit(x_train_scaled, y_train, \n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3171\u001b[0m           *args, **kwargs)\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3173\u001b[0;31m     \u001b[0mcache_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3175\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_cache_key\u001b[0;34m(self, args, kwargs, include_tensor_ranks_only)\u001b[0m\n\u001b[1;32m   2990\u001b[0m     \u001b[0;31m# Don't need to open an init_scope if the _cache_key call is in eager mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2991\u001b[0m     \u001b[0;31m# already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2992\u001b[0;31m     \u001b[0mexecuting_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2993\u001b[0m     \u001b[0mparent_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0mxla_context_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0;34m\"\"\"Returns True if current thread has eager executing enabled.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mones_rank_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model=make_model_1()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(beta_1 = 0.9, beta_2 = 0.999),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"1-2_model.h5\", save_best_only=True)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_scaled, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          callbacks=[model_checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [ 2 ]\n",
    "\n",
    "* **100**개의 뉴런을 가진 **은닉층** **20개**를 쌓아 심층 신경망을 만듭니다.\n",
    "* 모든 은닉층의 initializer는 **He 초기화**를, 활성화 함수는 **Elu** 함수를 사용합니다.\n",
    "* 출력층은 **10개**의 뉴런과 **소프트맥스 활성화** 함수를 사용합니다. \n",
    "* 출력층에서는 **initializer**를 사용하지 않습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_2():\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer((32*32*3)))\n",
    "\n",
    "    for _ in range(20):\n",
    "        model.add(tf.keras.layers.Dense(100, activation=\"relu\", kernel_initializer='he_normal'))  \n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 )\n",
    "\n",
    "* 옵티마이저는 **Adam**을 사용합니다. Adam의 파라미터 **beta1**, **beta2**를 0.9, 0.999로 초기화 합니다. \n",
    "* 콜백 ModelCheckpoint의 저장 이름을 **2-1_model.h5**로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.9612 - accuracy: 0.2608 - val_loss: 1.8718 - val_accuracy: 0.2720\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.8184 - accuracy: 0.3114 - val_loss: 1.7980 - val_accuracy: 0.3283\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.7519 - accuracy: 0.3489 - val_loss: 1.7362 - val_accuracy: 0.3557\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6860 - accuracy: 0.3835 - val_loss: 1.7069 - val_accuracy: 0.3974\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6484 - accuracy: 0.4040 - val_loss: 1.6803 - val_accuracy: 0.3962\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.6027 - accuracy: 0.4205 - val_loss: 1.6415 - val_accuracy: 0.4096\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5648 - accuracy: 0.4390 - val_loss: 1.6224 - val_accuracy: 0.4272\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.5330 - accuracy: 0.4515 - val_loss: 1.5827 - val_accuracy: 0.4419\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4949 - accuracy: 0.4687 - val_loss: 1.5879 - val_accuracy: 0.4302\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4539 - accuracy: 0.4812 - val_loss: 1.5896 - val_accuracy: 0.4360\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4338 - accuracy: 0.4901 - val_loss: 1.5399 - val_accuracy: 0.4536\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4016 - accuracy: 0.5024 - val_loss: 1.5491 - val_accuracy: 0.4590\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3797 - accuracy: 0.5101 - val_loss: 1.5193 - val_accuracy: 0.4697\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3556 - accuracy: 0.5199 - val_loss: 1.5675 - val_accuracy: 0.4559\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3487 - accuracy: 0.5211 - val_loss: 1.5487 - val_accuracy: 0.4696\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.3078 - accuracy: 0.5386 - val_loss: 1.5121 - val_accuracy: 0.4720\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2785 - accuracy: 0.5473 - val_loss: 1.5109 - val_accuracy: 0.4785\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2716 - accuracy: 0.5505 - val_loss: 1.5200 - val_accuracy: 0.4768\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2421 - accuracy: 0.5623 - val_loss: 1.5403 - val_accuracy: 0.4780\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2320 - accuracy: 0.5659 - val_loss: 1.5357 - val_accuracy: 0.4773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa07d4fe220>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model=make_model_2()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(beta_1 = 0.9, beta_2 = 0.999),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"2-1_model.h5\", save_best_only=True)\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_scaled, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          callbacks=[model_checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 )\n",
    "\n",
    "* 옵티마이저는 **Nadam**을 사용합니다. Ndam의 학습률을 **5e-5** 로 초기화합니다\n",
    "* 콜백 ModelCheckpoint의 저장 이름을 **2-2_model.h5**로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 2.0219 - accuracy: 0.2486 - val_loss: 1.8481 - val_accuracy: 0.3220\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7719 - accuracy: 0.3555 - val_loss: 1.7666 - val_accuracy: 0.3532\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6733 - accuracy: 0.3966 - val_loss: 1.6818 - val_accuracy: 0.3978\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5997 - accuracy: 0.4267 - val_loss: 1.6521 - val_accuracy: 0.4109\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5362 - accuracy: 0.4486 - val_loss: 1.6291 - val_accuracy: 0.4214\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4854 - accuracy: 0.4684 - val_loss: 1.6138 - val_accuracy: 0.4328\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4412 - accuracy: 0.4862 - val_loss: 1.5778 - val_accuracy: 0.4443\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4024 - accuracy: 0.5002 - val_loss: 1.5787 - val_accuracy: 0.4471\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.3636 - accuracy: 0.5133 - val_loss: 1.5720 - val_accuracy: 0.4468\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.3305 - accuracy: 0.5274 - val_loss: 1.5693 - val_accuracy: 0.4480\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.3002 - accuracy: 0.5362 - val_loss: 1.5750 - val_accuracy: 0.4524\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2653 - accuracy: 0.5501 - val_loss: 1.5670 - val_accuracy: 0.4561\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2386 - accuracy: 0.5577 - val_loss: 1.5781 - val_accuracy: 0.4532\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2125 - accuracy: 0.5669 - val_loss: 1.6007 - val_accuracy: 0.4510\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1826 - accuracy: 0.5785 - val_loss: 1.5925 - val_accuracy: 0.4601\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1565 - accuracy: 0.5885 - val_loss: 1.5953 - val_accuracy: 0.4626\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1257 - accuracy: 0.5998 - val_loss: 1.6164 - val_accuracy: 0.4583\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1061 - accuracy: 0.6052 - val_loss: 1.6268 - val_accuracy: 0.4573\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0815 - accuracy: 0.6153 - val_loss: 1.6418 - val_accuracy: 0.4641\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0580 - accuracy: 0.6238 - val_loss: 1.6787 - val_accuracy: 0.4574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa0310ded60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model=make_model_2()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Nadam(lr = 5e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"2-2_model.h5\", save_best_only=True)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_scaled, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          callbacks=[model_checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [  3 ] \n",
    "\n",
    "* **100**개의 뉴런을 가진 **은닉층** **20개**를 쌓아 심층 신경망을 만듭니다.\n",
    "* 모든 은닉층의 initializer는 **He 초기화**를, 활성화 함수는 **Elu** 함수를 사용합니다.\n",
    "* 모든 은닉층의 다음층에서 BatchNormaliztion을 수행합니다. \n",
    "* 출력층은 **10개**의 뉴런과 **소프트맥스 활성화** 함수를 사용합니다. \n",
    "* 출력층에서는 **initializer**를 사용하지 않습니다. \n",
    "* 출력층 다음층에서는 BatchNormalization을 수행하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_3():\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer((32*32*3)))\n",
    "\n",
    "    for _ in range(20):\n",
    "        model.add(tf.keras.layers.Dense(100, activation=\"elu\", kernel_initializer='he_normal'))  \n",
    "        tf.keras.layers.BatchNormalization()\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 옵티마이저는 **Nadam**을 사용합니다. Ndam의 학습률을 **5e-5** 로 초기화합니다\n",
    "* 콜백 ModelCheckpoint의 저장 이름을 **3_model.h5**로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 2.0969 - accuracy: 0.2585 - val_loss: 1.8654 - val_accuracy: 0.3194\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.7747 - accuracy: 0.3559 - val_loss: 1.7436 - val_accuracy: 0.3712\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.6510 - accuracy: 0.4064 - val_loss: 1.6728 - val_accuracy: 0.4026\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.5591 - accuracy: 0.4407 - val_loss: 1.6272 - val_accuracy: 0.4203\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4888 - accuracy: 0.4674 - val_loss: 1.6099 - val_accuracy: 0.4368\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.4263 - accuracy: 0.4904 - val_loss: 1.5877 - val_accuracy: 0.4405\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.3719 - accuracy: 0.5119 - val_loss: 1.6004 - val_accuracy: 0.4381\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3235 - accuracy: 0.5287 - val_loss: 1.6056 - val_accuracy: 0.4461\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.2749 - accuracy: 0.5487 - val_loss: 1.5869 - val_accuracy: 0.4542\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.2331 - accuracy: 0.5620 - val_loss: 1.6122 - val_accuracy: 0.4519\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1938 - accuracy: 0.5776 - val_loss: 1.6009 - val_accuracy: 0.4534\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.1544 - accuracy: 0.5919 - val_loss: 1.6220 - val_accuracy: 0.4534\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.1171 - accuracy: 0.6033 - val_loss: 1.6424 - val_accuracy: 0.4512\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0840 - accuracy: 0.6159 - val_loss: 1.6493 - val_accuracy: 0.4582\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0450 - accuracy: 0.6316 - val_loss: 1.6841 - val_accuracy: 0.4558\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.0115 - accuracy: 0.6432 - val_loss: 1.6850 - val_accuracy: 0.4558\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.9750 - accuracy: 0.6585 - val_loss: 1.7451 - val_accuracy: 0.4518\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9427 - accuracy: 0.6680 - val_loss: 1.7830 - val_accuracy: 0.4534\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.9097 - accuracy: 0.6822 - val_loss: 1.8268 - val_accuracy: 0.4490\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.8793 - accuracy: 0.6925 - val_loss: 1.8305 - val_accuracy: 0.4495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa012a57eb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model=make_model_3()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Nadam(lr = 5e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"3_model.h5\", save_best_only=True)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_scaled, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          callbacks=[model_checkpoint_cb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# [  4 ] \n",
    "\n",
    "* **100**개의 뉴런을 가진 **은닉층** **20개**를 쌓아 심층 신경망을 만듭니다.\n",
    "* 모든 은닉층의 initializer는 **르쿤 초기화**를, 활성화 함수는 **Selu** 함수를 사용합니다.\n",
    "* 출력층은 **10개**의 뉴런과 **소프트맥스 활성화** 함수를 사용합니다. \n",
    "* 출력층에서는 **initializer**를 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_4():\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer((32*32*3)))\n",
    "\n",
    "    for _ in range(20):\n",
    "        model.add(tf.keras.layers.Dense(100, activation=\"selu\", kernel_initializer='lecun_normal'))  \n",
    "        tf.keras.layers.BatchNormalization()\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 옵티마이저는 **Nadam**을 사용합니다. Ndam의 학습률을 **5e-5** 로 초기화합니다\n",
    "* 콜백 ModelCheckpoint의 저장 이름을 **4_model.h5**로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.8796 - accuracy: 0.3302 - val_loss: 1.7593 - val_accuracy: 0.3673\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.6525 - accuracy: 0.4105 - val_loss: 1.6548 - val_accuracy: 0.4152\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.5529 - accuracy: 0.4450 - val_loss: 1.6132 - val_accuracy: 0.4261\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4784 - accuracy: 0.4715 - val_loss: 1.5727 - val_accuracy: 0.4414\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.4190 - accuracy: 0.4944 - val_loss: 1.5507 - val_accuracy: 0.4520\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3667 - accuracy: 0.5107 - val_loss: 1.5244 - val_accuracy: 0.4583\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.3205 - accuracy: 0.5303 - val_loss: 1.5200 - val_accuracy: 0.4678\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2737 - accuracy: 0.5478 - val_loss: 1.5288 - val_accuracy: 0.4719\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.2341 - accuracy: 0.5593 - val_loss: 1.5279 - val_accuracy: 0.4742\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1965 - accuracy: 0.5758 - val_loss: 1.5123 - val_accuracy: 0.4793\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1600 - accuracy: 0.5852 - val_loss: 1.5306 - val_accuracy: 0.4771\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.1257 - accuracy: 0.5998 - val_loss: 1.5492 - val_accuracy: 0.4736\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0931 - accuracy: 0.6134 - val_loss: 1.5631 - val_accuracy: 0.4796\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 1.0616 - accuracy: 0.6241 - val_loss: 1.5746 - val_accuracy: 0.4792\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 1.0297 - accuracy: 0.6378 - val_loss: 1.5839 - val_accuracy: 0.4762\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 1.0008 - accuracy: 0.6467 - val_loss: 1.5985 - val_accuracy: 0.4755\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9709 - accuracy: 0.6573 - val_loss: 1.6085 - val_accuracy: 0.4724\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9431 - accuracy: 0.6645 - val_loss: 1.6262 - val_accuracy: 0.4767\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.9101 - accuracy: 0.6805 - val_loss: 1.6454 - val_accuracy: 0.4762\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.8833 - accuracy: 0.6874 - val_loss: 1.6718 - val_accuracy: 0.4727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ff10c9580>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "model=make_model_4()\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Nadam(lr = 5e-5),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# 콜백 선언\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"4_model.h5\", save_best_only=True)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_scaled, y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=20,\n",
    "          callbacks=[model_checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 5 ]\n",
    "\n",
    "* 지금까지 만든 6가지 모델을 불러오고 평가해 봅니다.\n",
    "* **tf.keras.models.load_model( )**을 통해 모델을 불러올 수 있습니다.\n",
    "* **model.evaluate( )**를 통해 모든 모델을 평가해 봅니다.\n",
    "* 불러오기 전에 아래 셀에서 각 모델의 특징을 간단히 메모하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* model_11: he 초기화, relu 활성화 함수, adam 옵티마이저 \n",
    "* model_12: adam 옵티마이저 베타값 초기화  \n",
    "* model_21: he 초기화, elu 활성화 함수, \n",
    "* model_22: 21과 같은데 옵티마이저 nadam으로 바꿈 \n",
    "* model_3: 22와 같은데, 은닉층 다음에는 항상 batchnormalization 함 \n",
    "* model_4: lecun 초기화, selu 활성화 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "\n",
    "model_11 = tf.keras.models.load_model(\"1-1_model.h5\")\n",
    "model_12 = tf.keras.models.load_model(\"1-2_model.h5\")\n",
    "model_21 = tf.keras.models.load_model(\"2-1_model.h5\")\n",
    "model_22 = tf.keras.models.load_model(\"2-2_model.h5\")\n",
    "model_3 = tf.keras.models.load_model(\"3_model.h5\")\n",
    "model_4 = tf.keras.models.load_model(\"4_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4979 - accuracy: 0.0801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4978880882263184, 0.08009999990463257]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가 \n",
    "\n",
    "\n",
    "model_11.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5259 - accuracy: 0.1253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5258526802062988, 0.12530000507831573]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_12.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4783 - accuracy: 0.1365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4782896041870117, 0.13650000095367432]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_21.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.5368 - accuracy: 0.1078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.536775827407837, 0.10779999941587448]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_22.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5801 - accuracy: 0.1042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5801317691802979, 0.10419999808073044]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 1.4985 - accuracy: 0.1015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4984612464904785, 0.1014999970793724]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
